{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the API selected will be used so that we load our ES db\n",
    "\n",
    "we ll use docker for elastic search and fill the details in the .ENV file\n",
    "\n",
    "- NYT-Times NewsWire API\n",
    "- NYT-Books API\n",
    "- GoodReads\n",
    "\n",
    "// end points\n",
    "// list of book categories : https://api.nytimes.com/svc/books/v3/lists/names.json\n",
    "// number of reviewed book : https://api.nytimes.com/svc/books/v3/lists/best-sellers/history.json\n",
    "// good reads : https://www.goodreads.com/book/review_counts.json\n",
    "//\n",
    "\n",
    "// need to establish the following :\n",
    "//1. connection to the ES container\n",
    "//\n",
    "//2. loading the api request from the two api\n",
    "//2. 1 for each API define loops and requirements\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Connection to the container // Windows installation\n",
    "\n",
    "1.Install Docker: Download and install Docker Desktop for Windows from the official Docker website. Follow the installation instructions specific to your Windows version.\n",
    "2.Launch Docker: Once Docker is installed, launch Docker Desktop from the start menu or desktop shortcut. Make sure it's running before proceeding to the next steps.\n",
    "3.Open a Command Prompt: Open the Command Prompt or PowerShell on your Windows machine.\n",
    "4.Pull the Elasticsearch Docker Image: Use the following command to pull the official Elasticsearch Docker image from Docker Hub:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "docker pull docker.elastic.co/elasticsearch/elasticsearch:8.8.1\n",
    "\n",
    "5.Create a Docker Container\n",
    "docker run -d --name elasticsearch_container -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" docker.elastic.co/elasticsearch/elasticsearch:8.8.1\n",
    "docker run -d --name elasticsearch  -v /data/dump/:/usr/share/elasticsearch/data -p 9400:9400 -p 9500:9200 -e \"discovery.type=single-node\" elasticsearch:8.8.1\n",
    "docker run -d --name elasticsearch761v2  -v /data/dump/:/usr/share/elasticsearch/data -p 9400:9400 -p 9500:9200 -e \"discovery.type=single-node\" elasticsearch:7.6.1\n",
    "\n",
    "docker run --name elasticSearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" docker.elastic.co/elasticsearch/elasticsearch:7.5.2\n",
    "\n",
    "6.Verify Elasticsearch Installation: Open your web browser and navigate to http://localhost:9200.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the connection is established we want to analyse in details the API and load them one by one without overloading the API from NYT or GoodReads\n",
    "\n",
    "To interact with ES firstly you need to : pip install elasticsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'resource_already_exists_exception', 'index [nyt-newswire/rB0uZqZ-SUqNQZ0vKsRnbA] already exists')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/cedricsoares/Documents/Formation/Datascientest/ny_times/notebooks/ES_load.ipynb Cellule 4\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cedricsoares/Documents/Formation/Datascientest/ny_times/notebooks/ES_load.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m newswire_mapping \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cedricsoares/Documents/Formation/Datascientest/ny_times/notebooks/ES_load.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m'\u001b[39m: {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cedricsoares/Documents/Formation/Datascientest/ny_times/notebooks/ES_load.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m: {\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cedricsoares/Documents/Formation/Datascientest/ny_times/notebooks/ES_load.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cedricsoares/Documents/Formation/Datascientest/ny_times/notebooks/ES_load.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cedricsoares/Documents/Formation/Datascientest/ny_times/notebooks/ES_load.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m  \u001b[39m# Create the index\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cedricsoares/Documents/Formation/Datascientest/ny_times/notebooks/ES_load.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m response \u001b[39m=\u001b[39m es\u001b[39m.\u001b[39;49mindices\u001b[39m.\u001b[39;49mcreate(index\u001b[39m=\u001b[39;49mindex_name, mappings\u001b[39m=\u001b[39;49mnewswire_mapping)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cedricsoares/Documents/Formation/Datascientest/ny_times/notebooks/ES_load.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Check the response\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cedricsoares/Documents/Formation/Datascientest/ny_times/notebooks/ES_load.ipynb#W3sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mif\u001b[39;00m response[\u001b[39m'\u001b[39m\u001b[39macknowledged\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/envs/dst_elastic/lib/python3.11/site-packages/elasticsearch/_sync/client/utils.py:414\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m api(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/dst_elastic/lib/python3.11/site-packages/elasticsearch/_sync/client/indices.py:517\u001b[0m, in \u001b[0;36mIndicesClient.create\u001b[0;34m(self, index, aliases, error_trace, filter_path, human, mappings, master_timeout, pretty, settings, timeout, wait_for_active_shards)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m __body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     __headers[\u001b[39m\"\u001b[39m\u001b[39mcontent-type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 517\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperform_request(  \u001b[39m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m    518\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPUT\u001b[39;49m\u001b[39m\"\u001b[39;49m, __path, params\u001b[39m=\u001b[39;49m__query, headers\u001b[39m=\u001b[39;49m__headers, body\u001b[39m=\u001b[39;49m__body\n\u001b[1;32m    519\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/dst_elastic/lib/python3.11/site-packages/elasticsearch/_sync/client/_base.py:389\u001b[0m, in \u001b[0;36mNamespacedClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperform_request\u001b[39m(\n\u001b[1;32m    379\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    380\u001b[0m     method: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[39m# Use the internal clients .perform_request() implementation\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[39m# so we take advantage of their transport options.\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mperform_request(\n\u001b[1;32m    390\u001b[0m         method, path, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders, body\u001b[39m=\u001b[39;49mbody\n\u001b[1;32m    391\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/dst_elastic/lib/python3.11/site-packages/elasticsearch/_sync/client/_base.py:320\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    318\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[39m.\u001b[39mget(meta\u001b[39m.\u001b[39mstatus, ApiError)(\n\u001b[1;32m    321\u001b[0m         message\u001b[39m=\u001b[39mmessage, meta\u001b[39m=\u001b[39mmeta, body\u001b[39m=\u001b[39mresp_body\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    324\u001b[0m \u001b[39m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verified_elasticsearch:\n\u001b[1;32m    326\u001b[0m     \u001b[39m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: BadRequestError(400, 'resource_already_exists_exception', 'index [nyt-newswire/rB0uZqZ-SUqNQZ0vKsRnbA] already exists')"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "es = Elasticsearch(hosts = \"http://@localhost:9200\")\n",
    "\n",
    "\n",
    "index_name = 'nyt-newswire'\n",
    "newswire_mapping = {\n",
    "        'properties': {\n",
    "            'abstract': {'type': 'text', 'analyzer': 'english'},\n",
    "            'byline': {'type': 'text', 'analyzer': 'english'},\n",
    "            'created_date': {'type': 'date'},\n",
    "            'des_facet': {'type': 'keyword'},\n",
    "            'first_published_date': {'type': 'date'},\n",
    "            'geo_facet': {'type': 'keyword'},\n",
    "            'item_type': {'type': 'keyword'},\n",
    "            'kicker': {'type': 'text'},\n",
    "            'material_type_facet': {'type': 'keyword'},\n",
    "            'multimedia': {\n",
    "                'type': 'nested',\n",
    "                'properties': {\n",
    "                    'caption': {'type': 'text', 'analyzer': 'english'},\n",
    "                    'copyright': {'type': 'text', 'analyzer': 'english'},\n",
    "                    'format': {'type': 'keyword'},\n",
    "                    'height': {'type': 'integer'},\n",
    "                    'subtype': {'type': 'keyword'},\n",
    "                    'type': {'type': 'keyword'},\n",
    "                    'url': {'type': 'text', 'analyzer': 'english'},\n",
    "                    'width': {'type': 'integer'}\n",
    "                }\n",
    "            },\n",
    "            'org_facet': {'type': 'keyword'},\n",
    "            'per_facet': {'type': 'keyword'},\n",
    "            'published_date': {'type': 'date'},\n",
    "            'section': {'type': 'keyword'},\n",
    "            'slug_name': {'type': 'keyword'},\n",
    "            'source': {'type': 'text', 'analyzer': 'english'},\n",
    "            'subheadline': {'type': 'text', 'analyzer': 'english'},\n",
    "            'subsection': {'type': 'keyword'},\n",
    "            'thumbnail_standard': {'type': 'text', 'analyzer': 'english'},\n",
    "            'title': {'type': 'text'},\n",
    "            'updated_date': {'type': 'date'},\n",
    "            'uri': {'type': 'keyword'},\n",
    "            'url': {'type': 'text', 'analyzer': 'english'}\n",
    "        }\n",
    "    }\n",
    "\n",
    "newswire_settings = {\n",
    "    \"number_of_shards\": 2,\n",
    "    \"number_of_replicas\": 2\n",
    "}\n",
    "\n",
    " # Create the index\n",
    "response = es.indices.create(index=index_name, mappings=newswire_mapping, \n",
    "                             settings=newswire_settings)\n",
    "\n",
    "# Check the response\n",
    "  \n",
    "if response['acknowledged']:\n",
    "    print('Index created successfully.')\n",
    "else:\n",
    "    print('Failed to create index.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "##########################################################################\n",
    "# we prepare the mapping for the new ESindex\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "# Mapping and index for yhr NYT - Book API \n",
    "##########################################################################\n",
    "#To be fixed \n",
    "\n",
    "\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "\n",
    "index_name = 'NYT-booksList'\n",
    "books_list_index_body = {\n",
    "    'properties': {\n",
    "        'amazon_product_url': {'type': 'keyword'},\n",
    "        'asterisk': {'type': 'integer'},\n",
    "        'bestsellers_date': {'type': 'date'},\n",
    "        'book_details': {\n",
    "            'type': 'nested',\n",
    "            'properties': {\n",
    "                'age_group': {'type': 'keyword'},\n",
    "                'author': {'type': 'keyword'},\n",
    "                'contributor': {'type': 'keyword'},\n",
    "                'contributor_note': {'type': 'text', 'analyzer': 'english'},\n",
    "                'description': {'type': 'text', 'analyzer': 'english'},\n",
    "                'price': {'type': 'float'},\n",
    "                'primary_isbn10': {'type': 'keyword'},\n",
    "                'primary_isbn13': {'type': 'keyword'},\n",
    "                'publisher': {'type': 'text', 'analyzer': 'english'},\n",
    "                'title': {'type': 'text', 'analyzer': 'english'}\n",
    "            }\n",
    "        },\n",
    "        'dagger': {'type': 'integer'},\n",
    "        'display_name': {'type': 'keyword'},\n",
    "        'isbns': {\n",
    "            'type': 'nested',\n",
    "            'properties': {\n",
    "                'isbn10': {'type': 'keyword'},\n",
    "                'isbn13': {'type': 'keyword'}\n",
    "            }\n",
    "        },\n",
    "        'list_name': {'type': 'keyword'},\n",
    "        'published_date': {'type': 'date'},\n",
    "        'rank': {'type': 'integer'},\n",
    "        'rank_last_week': {'type': 'integer'},\n",
    "        'reviews': {\n",
    "            'type': 'nested',\n",
    "            'properties': {\n",
    "                'article_chapter_link': {'type': 'keyword'},\n",
    "                'book_review_link': {'type': 'keyword'},\n",
    "                'first_chapter_link': {'type': 'keyword'},\n",
    "                'sunday_review_link': {'type': 'keyword'}\n",
    "            }\n",
    "        },\n",
    "        'weeks_on_list': {'type': 'integer'}\n",
    "    }\n",
    "}\n",
    "\n",
    "book_list_settings = {\n",
    "    \"number_of_shards\": 2,\n",
    "    \"number_of_replicas\": 2\n",
    "}\n",
    "\n",
    "\n",
    " # Create the index\n",
    "response = es.indices.create(index=index_name, mappings=books_list_index_body,\n",
    "                             settings=book_list_settings)\n",
    "\n",
    "# Check the response\n",
    "  \n",
    "if response['acknowledged']:\n",
    "    print('Index created successfully.')\n",
    "else:\n",
    "    print('Failed to create index.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "##########################################################################\n",
    "# we prepare the mapping for the new ESindex\n",
    "##########################################################################\n",
    "##########################################################################\n",
    "# Mapping and index for yhr NYT - Book API -- best sellers\n",
    "##########################################################################\n",
    "#To be fixed \n",
    "\n",
    "\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "\n",
    "index_name = 'NYT-books-best-sellers'\n",
    "BS_books_index_body = {\n",
    "    'properties': {\n",
    "    'title': {'type': 'text', 'analyzer': 'english'},\n",
    "    'description': {'type': 'text', 'analyzer': 'english'},\n",
    "    'contributor': {'type': 'text', 'analyzer': 'english'},\n",
    "    'author': {'type': 'text', 'analyzer': 'english'},\n",
    "    'contributor_note': {'type': 'text', 'analyzer': 'english'},\n",
    "    'price': {'type': 'float'},\n",
    "    'age_group': {'type': 'keyword'},\n",
    "    'publisher': {'type': 'text', 'analyzer': 'english'},\n",
    "    'isbns': {\n",
    "        'type': 'nested',\n",
    "        'properties': {\n",
    "            'isbn10': {'type': 'keyword'},\n",
    "            'isbn13': {'type': 'keyword'},\n",
    "        }\n",
    "    },\n",
    "    'ranks_history': {\n",
    "        'type': 'nested',\n",
    "        'properties': {\n",
    "            'primary_isbn10': {'type': 'keyword'},\n",
    "            'primary_isbn13': {'type': 'keyword'},\n",
    "            'rank': {'type': 'integer'},\n",
    "            'list_name': {'type': 'text', 'analyzer': 'english'},\n",
    "            'display_name': {'type': 'text', 'analyzer': 'english'},\n",
    "            'published_date': {'type': 'date'},\n",
    "            'bestsellers_date': {'type': 'date'},\n",
    "            'weeks_on_list': {'type': 'integer'},\n",
    "            'ranks_last_week': {'type': 'integer', 'null_value': None},\n",
    "            'asterisk': {'type': 'integer'},\n",
    "            'dagger': {'type': 'integer'},\n",
    "        }\n",
    "    },\n",
    "    'reviews': {\n",
    "        'type': 'nested',\n",
    "        'properties': {\n",
    "            'book_review_link': {'type': 'keyword'},\n",
    "            'first_chapter_link': {'type': 'keyword'},\n",
    "            'sunday_review_link': {'type': 'keyword'},\n",
    "            'article_chapter_link': {'type': 'keyword'},\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "books_settings = {\n",
    "    \"number_of_shards\": 2,\n",
    "    \"number_of_replicas\": 2\n",
    "}\n",
    "\n",
    "\n",
    " # Create the index\n",
    "response = es.indices.create(index=index_name, mappings=BS_books_index_body, \n",
    "                             settings=books_settings)\n",
    "\n",
    "# Check the response\n",
    "  \n",
    "if response['acknowledged']:\n",
    "    print('Index created successfully.')\n",
    "else:\n",
    "    print('Failed to create index.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the requests and loading in the Elastic search DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pprint\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "# NEWSWIRE API\n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "\n",
    "#Define the variables used in the API\n",
    "#Get the list of sections needed to call the API Newswire\n",
    "reqSections =  requests.get(f'https://api.nytimes.com/svc/news/v3/content/section-list.json?&api-key={api_key}')\n",
    "sectionsList= [item['section'] for item in reqSections.json()['results']]\n",
    "print(sectionsList)\n",
    "\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "# for tests ONLY ###\n",
    "########################################################\n",
    "sectionsList = sectionsList[:2]\n",
    "print(sectionsList)\n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "\n",
    "# iterate through the list \n",
    "for section in sectionsList:\n",
    "     \n",
    "    # Create a connection to Elasticsearch  \n",
    "\n",
    "    #Request the Api\n",
    "    content = requests.get(f'https://api.nytimes.com/svc/news/v3/content/all/{section}.json?&api-key={api_key}')\n",
    "    #save into the ES DB\n",
    "    res = content.json()\n",
    "    pp.pprint(res) \n",
    "    docs = res['results']\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare documents for indexing\n",
    "    actions = [\n",
    "        {\n",
    "            '_index': index_name,\n",
    "            '_source': doc\n",
    "         }\n",
    "        for doc in docs\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    # Define an index and document type for ES\n",
    "    index_name = 'NYT-newswire'\n",
    "\n",
    "    # Bulk index the documents\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    index_body = {\n",
    "        'settings': {\n",
    "            'number_of_shards': 1,\n",
    "            'number_of_replicas': 0\n",
    "        },\n",
    "        'mappings': {\n",
    "            'properties': {\n",
    "                'field1': {'type': 'text'},\n",
    "                'field2': {'type': 'keyword'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #response = es.bulk(index=index_name, body=actions, headers=headers)\n",
    "\n",
    "\n",
    "  \n",
    "    # Check the response\n",
    "    if response['result'] == 'created':\n",
    "        print(f'{section} saved successfully')\n",
    "    else:\n",
    "        print('Failed to save content.')\n",
    "    \n",
    "    ######################################################\n",
    "    time.sleep(2) ##### TO MODIFY ACCORDING API ALLOWANCE\n",
    "    ######################################################\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pprint\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "# BOOKS API\n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "\n",
    "#Define the variables used in the API\n",
    "#Get the list of sections needed to call the API Newswire\n",
    "reqBookList = requests.get(f\"https://api.nytimes.com/svc/books/v3/lists/names.json?api-key={api_key}\")\n",
    "booksList= [item['list_name'] for item in reqBookList.json()['results']]\n",
    "\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "# for tests ONLY ###\n",
    "########################################################\n",
    "booksList = booksList[:2]\n",
    "print(booksList)\n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "\n",
    "# iterate through the list \n",
    "for blist in booksList:\n",
    "     \n",
    "    # Create a connection to Elasticsearch  \n",
    "\n",
    "    #Request the Api\n",
    "    content = requests.get(f\"https://api.nytimes.com/svc/books/v3/lists.json?list={blist}&api-key={api_key}\")\n",
    "    #save into the ES DB\n",
    "    res = content.json()\n",
    "    pp.pprint(res) \n",
    "    docs = res['results']\n",
    "\n",
    "\n",
    "    \"\"\"    \n",
    "    # Prepare documents for indexing\n",
    "    actions = [\n",
    "        {\n",
    "            '_index': index_name,\n",
    "            '_source': doc\n",
    "         }\n",
    "        for doc in docs\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    # Define an index and document type for ES\n",
    "    index_name = 'NYT-newswire'\n",
    "\n",
    "    # Bulk index the documents\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    index_body = {\n",
    "        'settings': {\n",
    "            'number_of_shards': 1,\n",
    "            'number_of_replicas': 0\n",
    "        },\n",
    "        'mappings': {\n",
    "            'properties': {\n",
    "                'field1': {'type': 'text'},\n",
    "                'field2': {'type': 'keyword'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #response = es.bulk(index=index_name, body=actions, headers=headers)\n",
    "\n",
    "\n",
    "  \n",
    "    # Check the response\n",
    "    if response['result'] == 'created':\n",
    "        print(f'{section} saved successfully')\n",
    "    else:\n",
    "        print('Failed to save content.')\n",
    "    \n",
    "    \"\"\"\n",
    "    ######################################################\n",
    "    time.sleep(1) ##### TO MODIFY ACCORDING API ALLOWANCE\n",
    "    ######################################################\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
